# configs/config.yaml

# 실험 설정
experiment_name: "dialogue-summarization"

# 기본 설정들
defaults:
  - dataset: dialogsum  # 기본 데이터셋
  - model: llama        # 기본 모델
  - trainer: train     # 학습 설정
  - _self_

# 경로 설정
paths:
  log_dir: "outputs/logs/${experiment_name}"
  data_dir: "data"

# 전처리 설정
preprocessing:
  max_length: 512
  clean_text: true
  remove_special_chars: true

# 미세조정 전략 설정
finetune_strategy:
  # 기본 설정
  gradient_checkpointing: true
  freeze_embeddings: true
  
  # 학습할 레이어 설정
  unfreeze_layers:
    - "model.embed_tokens"
    - "model.layers.0"
    - "model.layers.1"
    - "model.norm"
    - "lm_head"

  # 양자화 설정
  quantization: "none"

# 메트릭 설정
metrics:
  # ROUGE 설정
  rouge:
    enabled: true
    types: ["rouge1", "rouge2", "rougeL"]
    use_stemmer: true
    use_aggregator: false
    lowercase: true
  
  # BLEU 설정
  bleu:
    enabled: false
    smooth_method: "exp"
    
  # BERTScore 설정
  bertscore:
    enabled: false
    model_type: "microsoft/deberta-xlarge-mnli"
    batch_size: 8
    
  # METEOR 설정
  meteor:
    enabled: false
    
  # BLEURT 설정
  bleurt:
    enabled: false
    checkpoint: "bleurt-base-128"
    batch_size: 8


#
